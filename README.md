# ğŸ™ Chat with a Git Repo

Interact with your codebase using natural language! Upload a GitHub repository URL or a `.zip` file of your project and ask questions like:

- "What does this repo do?"
- "Summarize the logic in `main.py`"
- "Which files handle authentication?"

Powered entirely by local models using [Ollama](https://ollama.com/) and [LangChain](https://python.langchain.com/).

---

## ğŸš€ Features

- ğŸ§  Local LLMs via Ollama (Mistral, LLaMA2, Qwen, etc.)
- ğŸ” Automatic repo indexing using sentence-transformer embeddings
- ğŸ“¦ Upload public GitHub repos or private `.zip` archives
- ğŸ’¬ Ask questions about your codebase
- ğŸ§° No API keys required (fully offline)

---

## ğŸ› ï¸ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

Make sure you have [Ollama installed](https://ollama.com/download) and running:

```bash
ollama run mistral
```

---

## ğŸ§ª Usage

```bash
streamlit run app.py
```

Then in the UI:
1. Choose input method (GitHub URL or `.zip`)
2. Select or type an Ollama model
3. Ask any question about your repo!

---

## ğŸ“Œ Example Questions

- "Explain how the data pipeline works."
- "What is the purpose of `config.yaml`?"
- "Where is the entrypoint for this app?"

---

## ğŸ§© Supported File Types

- `.py`, `.js`, `.ts`, `.md`, `.txt`, `.java`, `.go`

---

## ğŸ¤– LLM Compatibility

Tested with:
- `mistral`
- `llama2`
- `qwen3:0.6b`
- `gemma`

Add your own via:
```bash
ollama pull <model_name>
```

---

## ğŸ“œ License

MIT License
